{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LAB2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-oBWtb7gyUlh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Penguins data\n",
        "#https://allisonhorst.github.io/palmerpenguins/ \n",
        "\n",
        "df = pd.read_csv(\"penguins.csv\")\n",
        "df = df.dropna()\n",
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_R2LIgH9d-Q",
        "outputId": "7a988268-c67d-4712-c441-c45c97e3e115"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "species               object\n",
              "island                object\n",
              "bill_length_mm       float64\n",
              "bill_depth_mm        float64\n",
              "flipper_length_mm    float64\n",
              "body_mass_g          float64\n",
              "sex                   object\n",
              "year                   int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_columns = []\n",
        "categorical_columns = []\n",
        "for i in df:\n",
        "  if(len(df[i].unique())>3):\n",
        "    numeric_columns.append(i)\n",
        "  else:\n",
        "    categorical_columns.append(i)\n",
        "\n",
        "def encode(df):\n",
        "  for i in categorical_columns:\n",
        "      df[i] = pd.Categorical(df[i],df[i].unique())\n",
        "      df[i] = df[i].cat.codes\n",
        "  return df\n",
        "df = encode(df)\n",
        "df_Y = df.pop('species')\n",
        "categorical_columns.remove('species')\n",
        "print(numeric_columns)\n",
        "print(categorical_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKdTDquxJ_KX",
        "outputId": "94e522ab-4994-457f-a25b-8025fb11e5ae"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
            "['island', 'sex', 'year']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_X,test_X,train_Y,test_Y = train_test_split(df,df_Y,test_size = 0.4,random_state = 100)\n",
        "print(train_X.shape)\n",
        "print(test_X.shape)\n",
        "type(train_X)\n",
        "type(test_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7IoFHwPqZQF",
        "outputId": "d833c412-3aa8-4b60-fd60-634d93d3f839"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(199, 7)\n",
            "(134, 7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree Implementation\n",
        "class Node():\n",
        "  def __init__(self,feature=None,Gain=None,split_val=None,left=None,right=None,value=None):\n",
        "    self.feature = feature\n",
        "    self.Gain = Gain\n",
        "    self.split_val = split_val\n",
        "    self.left = left\n",
        "    self.right = right\n",
        "    self.value = value\n",
        "class DecisionTreeClassifier():\n",
        "  def __init__(self,max_depth,categorical_cols,numeric_cols):\n",
        "    self.root = None\n",
        "    self.max_depth = max_depth\n",
        "    self.numeric_cols = numeric_cols\n",
        "    self.categorical_col = categorical_cols\n",
        "\n",
        "  def build(self,X,Y,depth):\n",
        "    max_Gain = -1e9+5\n",
        "    #print(depth)\n",
        "    if depth<=self.max_depth:\n",
        "      best = {}\n",
        "      ##print(depth)\n",
        "      for i in self.categorical_col:\n",
        "        temp = self.find_best_split(X,Y,i)\n",
        "        ##print(temp)\n",
        "        #print(i,temp['Gain'])\n",
        "        if temp['Gain']>max_Gain:\n",
        "          best = temp\n",
        "          max_Gain = temp['Gain']\n",
        "      #print('\\n')\n",
        "      for i in self.numeric_cols:\n",
        "        temp = self.find_best_split(X,Y,i,feature_type = \"numeric\")\n",
        "        #print(i,temp['Gain'])\n",
        "        if temp['Gain']>max_Gain:\n",
        "          best = temp\n",
        "          max_Gain = temp['Gain']\n",
        "      #print('\\n')\n",
        "      #print(\"best split\" ,best['Feature'])\n",
        "      if(best['Gain']>0):\n",
        "        left_tree = self.build(best['leftX'],best['leftY'],depth+1)\n",
        "        right_tree = self.build(best['rightX'],best['rightY'],depth+1)\n",
        "        #print(\"done1\")\n",
        "        return Node(best['Feature'],best['Gain'],best['split_val'],left_tree,right_tree)\n",
        "    a = list(Y['species'])\n",
        "    #print(a)\n",
        "    val = max(a,key=a.count)\n",
        "    return Node(value = val)\n",
        "  #finding the best split\n",
        "  def find_best_split(self,X,Y,feature_name,feature_type = \"categorical\"):\n",
        "    best = {}\n",
        "    max_Gain = -1e9+5\n",
        "    best['Gain'] = 0\n",
        "    if feature_type == \"categorical\":\n",
        "      ##print(type(X),feature_name)\n",
        "      types = X[feature_name].unique()\n",
        "      for values in types:\n",
        "        left_X ,left_Y,right_X,right_Y = self.split(X,Y,feature_name,values)\n",
        "        if(len(left_X)>0 and len(right_X)>0):\n",
        "          Gain = self.information_gain_IE3(Y,left_Y,right_Y)\n",
        "          if Gain>max_Gain:\n",
        "            best['Feature'] = feature_name\n",
        "            best['Gain'] = Gain\n",
        "            best['split_val'] = values\n",
        "            best['leftX'] = left_X\n",
        "            best['rightX'] = right_X\n",
        "            best['leftY'] = left_Y\n",
        "            best['rightY'] = right_Y\n",
        "            max_Gain = Gain\n",
        "    else:\n",
        "      types = list(X[feature_name].unique())\n",
        "      types.sort()\n",
        "      ##print(types)\n",
        "      for i in range(len(types)-1):\n",
        "        avg_val = (types[i]+types[i+1])/2\n",
        "        ##print(feature_name,avg_val)\n",
        "        left_X ,left_Y,right_X,right_Y = self.split(X,Y,feature_name,avg_val)\n",
        "        if(len(left_X)>0 and len(right_X)>0):\n",
        "          Gain = self.information_gain_IE3(Y,left_Y,right_Y)\n",
        "          if Gain>max_Gain:\n",
        "            best['Feature'] = feature_name\n",
        "            best['Gain'] = Gain\n",
        "            best['split_val'] = avg_val\n",
        "            best['leftX'] = left_X\n",
        "            best['rightX'] = right_X\n",
        "            best['leftY'] = left_Y\n",
        "            best['rightY'] = right_Y\n",
        "            max_Gain = Gain\n",
        "    return best\n",
        "  #splitting the dataframe with respect to a value\n",
        "  def split(self,X,Y,feature_name,value):\n",
        "    dataframe = pd.concat([X,Y],axis=1)\n",
        "    left = dataframe[dataframe[feature_name]<=value]\n",
        "    right = dataframe[dataframe[feature_name]>value]\n",
        "    left_X = left.iloc[:,:-1]\n",
        "    left_Y = left.iloc[:,-1:]\n",
        "    right_X = right.iloc[:,:-1]\n",
        "    right_Y = right.iloc[:,-1:]\n",
        "    return left_X,left_Y,right_X,right_Y\n",
        "  #entropy calculation\n",
        "  def find_entropy(self,y):\n",
        "    entropy = 0\n",
        "    ##print(y)\n",
        "    n = len(y)\n",
        "    y =  np.array(y)\n",
        "    unique_y = np.unique(y)\n",
        "    for i in unique_y:\n",
        "      d = [j for j in y if j==i]\n",
        "      d = len(d)/n\n",
        "      entropy += -d*np.log2(d)\n",
        "    return entropy\n",
        "  \n",
        "  def information_gain_IE3(self,parent,left,right):\n",
        "    entropy_par = self.find_entropy(parent)\n",
        "    entropy_left = self.find_entropy(left)\n",
        "    entropy_right = self.find_entropy(right)\n",
        "    left_wt = len(left)/len(parent)\n",
        "    right_wt = len(right)/len(parent)\n",
        "    return entropy_par-(left_wt*entropy_left+right_wt*entropy_right)\n",
        "  #fitting the model\n",
        "  def fit(self,train_X,train_Y):\n",
        "    self.root = self.build(train_X,train_Y,0)\n",
        "\n",
        "  #predictions\n",
        "  def make_prediction(self,x,node):\n",
        "    if node.value!=None:\n",
        "      return node.value\n",
        "    #print(type(x),node.feature)\n",
        "    #print(type(x[node.feature]),x[node.feature])\n",
        "    a = list(x[node.feature])\n",
        "    #print(a)\n",
        "    if a[0]<=node.split_val:\n",
        "      return self.make_prediction(x,node.left)\n",
        "    else:\n",
        "      return self.make_prediction(x,node.right)\n",
        "  #test_X and test_Y are pandas dataframe\n",
        "  def predict(self,test_X,test_Y):\n",
        "    predictions = []\n",
        "    #print(len(test_X))\n",
        "    for i in range(len(test_X)):\n",
        "      a = test_X.iloc[i:i+1,:]\n",
        "      #print(a)\n",
        "      a = self.make_prediction(a,self.root)\n",
        "      predictions.append(a)\n",
        "    n = len(test_Y.unique())\n",
        "    confusion_mat = np.zeros((n,n))\n",
        "    for x,y in zip(predictions,test_Y):\n",
        "      confusion_mat[x,y]+=1\n",
        "    acc = (confusion_mat.diagonal().sum())/(len(test_Y))\n",
        "    class_wise_acc = confusion_mat.diagonal()/(confusion_mat.sum(axis=1))\n",
        "    prediction = {'Accuracy' : acc,'Predictions' : predictions,'Class-Wise Accuracy': class_wise_acc}\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "m0tZCBhPP9CA"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DecisionTreeClassifier(3,categorical_columns,numeric_columns)\n",
        "# print(model.categorical_col)\n",
        "# print(model.numeric_cols)\n",
        "model.fit(train_X,train_Y)"
      ],
      "metadata": {
        "id": "LXtGgDQMV2Jk"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predictions = model.predict(test_X,test_Y)\n",
        "print(\"Accuracy:\",predictions['Accuracy'])\n",
        "print(\"Class-Wise Accuracy\",predictions['Class-Wise Accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjSumSA91rEl",
        "outputId": "d8ce2670-769a-4e31-95e7-d3a52e86ea28"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9776119402985075\n",
            "Class-Wise Accuracy [0.96428571 0.98039216 1.        ]\n"
          ]
        }
      ]
    }
  ]
}